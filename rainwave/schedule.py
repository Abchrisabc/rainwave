import time
import pprint
import tornado.ioloop
import datetime

from backend import sync_to_front
from rainwave import events
from rainwave.events import election
from rainwave import playlist
from rainwave import listeners
from rainwave import request
from rainwave import user
from libs import db
from libs import config
from libs import cache
from libs import log

# Events for each station
current = {}
next = {}
history = {}

import pdb

class ScheduleIsEmpty(Exception):
	pass

def load():
	for sid in config.station_ids:
		current[sid] = cache.get_station(sid, "sched_current")
		# If our cache is empty, pull from the DB
		if not current[sid]:
			current[sid] = get_event_in_progress(sid)

		next[sid] = cache.get_station(sid, "sched_next")
		if not next[sid]:
			next[sid] = []
			manage_next(sid)

		history[sid] = cache.get_station(sid, "sched_history")
		if not history[sid]:
			# TODO: Have this load a list of empty "song" events, since this is a last resort
			history[sid] = []
			# Only loads elections but this should be good enough for history 99% of the time.
			for elec_id in db.c.fetch_list("SELECT elec_id FROM r4_elections WHERE elec_start_actual < %s ORDER BY elec_start_actual DESC LIMIT 5", (current[sid].start_actual,)):
				history[sid].insert(0, election.Election.load_by_id(elec_id))

def get_event_in_progress(sid):
	producer = get_current_producer(sid)
	evt = producer.load_event_in_progress()
	return evt

def get_current_producer(sid):
	return get_producer_at_time(sid, int(time.time()))

def get_producer_at_time(sid, at_time):
	# pdb.set_trace()
	sched_id = db.c.fetch_row(	"SELECT sched_id "
								"FROM r4_schedule "
								"WHERE sid = %s AND sched_start <= %s AND sched_end > %s "
								"ORDER BY sched_id "
								"LIMIT 1", (sid, at_time + 15, at_time))
	if sched_id:
		return events.event.BaseProducer.load_producer_by_id(sched_id)
	return election.ElectionProducer(sid)

def get_advancing_file(sid):
	return next[sid][0].get_filename()

def get_advancing_event(sid):
	return next[sid][0]

def get_current_file(sid):
	return current[sid].get_filename()

def get_current_event(sid):
	return current[sid]

def advance_station(sid):
	start_time = time.time()
	# If we need some emergency elections here
	if len(next[sid]) == 0:
		next[sid].append(_get_or_create_election(sid))

	start_time = time.time()
	next[sid][0].prepare_event()
	log.debug("advance", "Next[0] preparation time: %.6f" % (time.time() - start_time,))
	_update_schedule_memcache(sid)

	tornado.ioloop.IOLoop.instance().add_timeout(datetime.timedelta(milliseconds=150), lambda: post_process(sid))

def post_process(sid):
	start_time = time.time()
	playlist.prepare_cooldown_algorithm(sid)
	playlist.clear_updated_albums(sid)
	log.debug("post", "Playlist prepare time: %.6f" % (time.time() - start_time,))

	start_time = time.time()
	current[sid].finish()
	log.debug("post", "Current finish time: %.6f" % (time.time() - start_time,))

	start_time = time.time()
	last_song = current[sid].get_song()
	if last_song:
		db.c.update("INSERT INTO r4_song_history (sid, song_id) VALUES (%s, %s)", (sid, last_song.id))
	log.debug("post", "Last song insertion time: %s" % (time.time() - start_time,))

	start_time = time.time()
	history[sid].insert(0, current[sid])
	while len(history[sid]) > 5:
		history[sid].pop()
	log.debug("post", "History management: %.6f" % (time.time() - start_time,))

	start_time = time.time()
	current[sid] = next[sid].pop(0)
	current[sid].start_event()
	log.debug("advance", "Current management: %.6f" % (time.time() - start_time,))

	start_time = time.time()
	# update_cache updates both the line and expiry times
	request.update_cache(sid)
	# reduce song blocks has to come first, otherwise it wll reduce blocks generated by _create_elections
	playlist.reduce_song_blocks(sid)
	# add to the event list / update start times for events
	manage_next(sid)
	log.debug("advance", "Next management: %.6f" % (time.time() - start_time,))

	start_time = time.time()
	_add_listener_count_record(sid)
	_trim(sid)
	user.trim_listeners(sid)
	cache.update_user_rating_acl(sid, history[sid][0].get_song().id)
	user.unlock_listeners(sid)
	log.debug("advance", "User management: %.6f" % (time.time() - start_time,))

	start_time = time.time()
	playlist.warm_cooled_songs(sid)
	playlist.warm_cooled_albums(sid)
	log.debug("advance", "Cooldown warming: %.6f" % (time.time() - start_time,))

	_update_memcache(sid)
	sync_to_front.sync_frontend_all(sid)

# def refresh_schedule(sid):
# 	integrate_new_events(sid)
# 	sort_next(sid)
# 	_update_memcache(sid)
# 	sync_to_front.sync_frontend_all_timed(sid)

def _add_listener_count_record(sid):
	lc_guests = db.c.fetch_var("SELECT COUNT(*) FROM r4_listeners WHERE sid = %s AND listener_purge = FALSE AND user_id = 1", (sid,))
	lc_users = db.c.fetch_var("SELECT COUNT(*) FROM r4_listeners WHERE sid = %s AND listener_purge = FALSE AND user_id > 1", (sid,))
	lc_guests_active = db.c.fetch_var("SELECT COUNT(*) FROM r4_listeners WHERE sid = %s AND listener_purge = FALSE AND user_id = 1 AND listener_voted_entry IS NOT NULL", (sid,))
	lc_users_active = db.c.fetch_var("SELECT COUNT(*) FROM r4_listeners WHERE sid = %s AND listener_purge = FALSE AND user_id > 1 AND listener_voted_entry IS NOT NULL", (sid,))
	return db.c.update("INSERT INTO r4_listener_counts (sid, lc_guests, lc_users, lc_guests_active, lc_users_active) VALUES (%s, %s, %s, %s, %s)", (sid, lc_guests, lc_users, lc_guests_active, lc_users_active))

def _get_schedule_stats(sid):
	global next
	global current
	
	max_sched_id = 0
	end_time = int(time.time())
	if sid in current and current[sid]:
		max_sched_id = current[sid].id
		if current[sid].start:
			end_time = current[sid].start + current[sid].length()
		else:
			end_time += current[sid].length()
	max_elec_id = 0
	num_elections = 0

	if sid in next:
		for e in next[sid]:
			if e.is_election:
				num_elections += 1
				if e.id > max_elec_id:
					max_elec_id = e.id
			elif not e.is_election and e.id > max_sched_id:
				max_sched_id = e.id
			end_time += e.length()
	return (max_sched_id, max_elec_id, num_elections, end_time)

def manage_next(sid):
	max_sched_id, max_elec_id, num_elections, future_time = _get_schedule_stats(sid)
	next_producer = get_producer_at_time(sid, future_time)
	while len(next[sid]) < next_producer.plan_ahead_limit:
		next_event = next_producer.load_next_event()
		if next_event:
			next[sid].append(next_producer.load_next_event())
		else:
			ep = election.ElectionProducer(sid)
			next[sid].append(ep.load_next_event())
		future_time += next[sid][-1].length()
		next_producer = get_producer_at_time(sid, future_time)


def sort_next(sid, do_elections = False):
	return None;
	"""
	DEPRECATED AND DISABLED.  Sort the next events list, and calibrate the start points of each event.
	"""
	# global next
	# # Filter out any None events (this has happened, despite the fact that it shouldn't, due to caching and other issues.  I'm not perfect.)
	# # next[sid] = filter(None, next[sid])
	# if len(next[sid]) == 0:
	# 	log.warn("sort_next", "Length of next events on sid %s is %s [problem: is zero] :: %s" % (sid, len(next[sid]), next[sid]))
	# 	if config.get_station(sid, "num_planned_elections") > 0:
	# 		for i in range(0, config.get_station(sid, "num_planned_elections")):
	# 			_get_or_create_election(sid)
	# 	else:
	# 		return

	# # Rip out anything with a scheduled start time, so we can insert it at the most appropriate time in the flow later
	# # This resists admins tampering with the flow that would result in bouncing scheduled events too far behind their
	# # intended start time
	# timed_events = []
	# for i in range(len(next[sid]), 0):
	# 	if next[sid][i].start != 0:
	# 		timed_events.append(next[sid].pop(i))
	# # Sort events by their scheduled times.  In later loops this helps, since we only have to look at index 0 for the next event.
	# timed_events = sorted(timed_events, key=lambda e: e.start)

	# # This loop determines predicted start times and re-inserts scheduled/timed events in the most appropriate place
	# i = 0
	# num_elections = 0
	# while i < len(next[sid]):
	# 	# ARGH ARGH ARGH ARGH ARGH ARGH ARGH ARGH DIRTY DIRTY DIRTY DIRTY
	# 	if i == 0:
	# 		next[sid][i].start_predicted = current[sid].start_actual + current[sid].length()
	# 	else:
	# 		next[sid][i].start_predicted = next[sid][i - 1].start_predicted + next[sid][i - 1].length()
	# 	if (len(timed_events) > 0):
	# 		# Calculate what's closer to the closest timed event: before this event, or after this event
	# 		this_time_diff_to_event = abs(timed_events[0].start - next[sid][i].start_predicted)
	# 		next_time_diff_to_event = abs(timed_events[0].start - next[sid][i].start_predicted + next[sid][i].length())
	# 		# Our current point in the flow is sooner - insert the timed event here
	# 		if this_time_diff_to_event < next_time_diff_to_event:
	# 			timed_events[0].start_predicted = next[sid][i].start_predicted
	# 			next[sid][i].start_predicted += timed_events[0].length()
	# 			next[sid].insert(i, timed_events.pop(0))
	# 	if next[sid][i].is_election:
	# 		num_elections += 1
	# 	i += 1

	# if do_elections:
	# 	log.debug("sort_next", "Number of elections currently in next: %s" % num_elections)
	# 	# Create elections to append directly to next[sid] at the end, if we haven't hit the necessary number of elections yet
	# 	while num_elections < config.get_station(sid, "num_planned_elections"):
	# 		time_to_next = None
	# 		target_length = None
	# 		if len(timed_events) > 0:
	# 			time_to_next = timed_events[0].start - next[sid][-1].start_predicted
	# 			if time_to_next < (playlist.get_average_song_length(sid) * 1.5):
	# 				target_length = time_to_next
	# 			elif time_to_next < (playlist.get_average_song_length(sid) * 2.5):
	# 				target_length = playlist.get_average_song_length(sid)
	# 		elec = _get_or_create_election(sid, target_length=target_length)
	# 		num_elections += 1
	# 		# If the election length is longer than the predicted time to the timed event,
	# 		# it'd be more accurate to put the timed event BEFORE the created election
	# 		if time_to_next and elec.length() > time_to_next:
	# 			timed_events[0].start_predicted = next[sid][-1].start_predicted + next[sid][-1].length()
	# 			next[sid].append(timed_events.pop(0))
	# 		if len(next[sid]) > 0:
	# 			elec.start_predicted = next[sid][-1].start_predicted + next[sid][-1].length()
	# 		else:
	# 			elec.start_predicted = current[sid].start_predicted + current[sid].length()
	# 		next[sid].append(elec)

	# # We're going to have some leftover timed events that are just too far in the future
	# # for us to worry about at the moment.  We'll set their predicted start times to their scheduled
	# # start times and append them to the schedule.  Clients will have to decide how to deal
	# # with displaying them on their own.
	# while len(timed_events) > 0:
	# 	timed_events[0].start_predicted = timed_events[0].start
	# 	next[sid].append(timed_events.pop(0))

def _get_or_create_election(sid, start_time = None, target_length = None):
	max_sched_id, max_elec_id, num_elections, next_end_time = _get_schedule_stats(sid)

	unused_elecs = event.Election.load_unused(sid, min_elec_id=max_elec_id, limit=1)
	if len(unused_elecs) > 0:
		log.debug("get_election", "SID %s returning unused election ID %s" % (sid, unused_elecs[0].id))
		return unused_elecs[0]
	else:
		return _create_election(sid, start_time, target_length)

def _trim(sid):
	# Deletes any events in the schedule and elections tables that are old, according to the config
	current_time = int(time.time())
	db.c.update("DELETE FROM r4_schedule WHERE sched_start_actual <= %s", (current_time - config.get("trim_event_age"),))
	db.c.update("DELETE FROM r4_elections WHERE elec_start_actual <= %s", (current_time - config.get("trim_election_age"),))
	max_history_id = db.c.fetch_var("SELECT MAX(songhist_id) FROM r4_song_history")
	db.c.update("DELETE FROM r4_song_history WHERE songhist_id <= %s", (max_history_id - config.get("trim_history_length"),))

def _update_schedule_memcache(sid):
	cache.set_station(sid, "sched_current", current[sid], True)
	cache.set_station(sid, "sched_next", next[sid], True)
	cache.set_station(sid, "sched_history", history[sid], True)

def _update_memcache(sid):
	_update_schedule_memcache(sid)
	cache.set_station(sid, "sched_current_dict", current[sid].to_dict(), True)
	next_dict_list = []
	for event in next[sid]:
		next_dict_list.append(event.to_dict())
	cache.set_station(sid, "sched_next_dict", next_dict_list, True)
	history_dict_list = []
	for event in history[sid]:
		history_dict_list.append(event.to_dict())
	cache.set_station(sid, "sched_history_dict", history_dict_list, True)
	cache.prime_rating_cache_for_events([ current[sid] ] + next[sid] + history[sid])
	cache.set_station(sid, "listeners_current", listeners.get_listeners_dict(sid), True)
	cache.set_station(sid, "album_diff", playlist.get_updated_albums_dict(sid), True)
	playlist.clear_updated_albums(sid)
	cache.set_station(sid, "all_albums", playlist.get_all_albums_list(sid), True)
	cache.set_station(sid, "all_artists", playlist.get_all_artists_list(sid), True)

	all_stations = {}
	for other_sid in config.station_ids:
		other_station = cache.get_station(other_sid, "sched_current_dict")
		if other_station:
			all_stations[other_sid] = {}
			if other_station['name']:
				all_stations[other_sid]['title'] = other_station['name']
				all_stations[other_sid]['album'] = ""
				all_stations[other_sid]['art']
			else:
				all_stations[other_sid]['title'] = other_station['songs'][0]['title']
				all_stations[other_sid]['album'] = other_station['songs'][0]['albums'][0]['name']
				all_stations[other_sid]['art'] = other_station['songs'][0]['albums'][0]['art']
			all_stations[other_sid]['end'] = other_station['end']
	cache.set("all_stations_info", all_stations, True)