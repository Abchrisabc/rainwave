import time
import pprint
import tornado.ioloop
import datetime

from backend import sync_to_front
from rainwave import events
from rainwave import playlist
from rainwave import listeners
from rainwave import request
from rainwave import user
from libs import db
from libs import config
from libs import cache
from libs import log

from rainwave.events import election

# This is to make sure the code gets loaded and producers get registered
import rainwave.events.oneup
import rainwave.events.pvpelection
import rainwave.events.shortest_election

# Events for each station
current = {}
next = {}
history = {}

import pdb

class ScheduleIsEmpty(Exception):
	pass

def load():
	for sid in config.station_ids:
		current[sid] = cache.get_station(sid, "sched_current")
		# If our cache is empty, pull from the DB
		if not current[sid]:
			current[sid] = get_event_in_progress(sid)
		if not current[sid]:
			raise Exception("Could not load any events!")

		next[sid] = cache.get_station(sid, "sched_next")
		if not next[sid]:
			next[sid] = []
			manage_next(sid)

		history[sid] = cache.get_station(sid, "sched_history")
		if not history[sid]:
			history[sid] = []
			for song_id in db.c.fetch_list("SELECT song_id FROM r4_song_history WHERE sid = %s ORDER BY songhist_time DESC LIMIT 5", (sid,)):
				history[sid].insert(0, events.event.SingleSong(song_id, sid))

def get_event_in_progress(sid):
	producer = get_current_producer(sid)
	evt = producer.load_event_in_progress()
	return evt

def get_current_producer(sid):
	return get_producer_at_time(sid, int(time.time()))

def get_producer_at_time(sid, at_time):
	to_ret = None
	sched_id = db.c.fetch_var(	"SELECT sched_id "
								"FROM r4_schedule "
								"WHERE sid = %s AND sched_start <= %s AND sched_end > %s "
								"ORDER BY sched_id DESC "
								"LIMIT 1", (sid, at_time + 20, at_time))
	try:
		to_ret = events.event.BaseProducer.load_producer_by_id(sched_id)
	except Exception as e:
		log.warn("get_producer", "Failed to obtain producer.")
		log.exception("get_producer", "Failed to get an appropriate producer.", e)
	if not to_ret:
		return election.ElectionProducer(sid)
	return to_ret

def get_advancing_file(sid):
	return next[sid][0].get_filename()

def get_advancing_event(sid):
	return next[sid][0]

def get_current_file(sid):
	return current[sid].get_filename()

def get_current_event(sid):
	return current[sid]

def advance_station(sid):
	db.c.start_transaction()
	try:
		start_time = time.time()
		# If we need some emergency elections here
		if len(next[sid]) == 0:
			manage_next(sid)

		while next[sid][0].used:
			next[sid].pop()
			if len(next[sid]) == 0:
				manage_next(sid)		

		start_time = time.time()
		next[sid][0].prepare_event()
		db.c.commit()

		log.debug("advance", "Next[0] preparation time: %.6f" % (time.time() - start_time,))

		tornado.ioloop.IOLoop.instance().add_timeout(datetime.timedelta(milliseconds=150), lambda: post_process(sid))
	except:
		db.c.rollback()
		raise

def post_process(sid):
	try:
		db.c.start_transaction()
		start_time = time.time()
		playlist.prepare_cooldown_algorithm(sid)
		playlist.clear_updated_albums(sid)
		log.debug("post", "Playlist prepare time: %.6f" % (time.time() - start_time,))

		start_time = time.time()
		current[sid].finish()
		log.debug("post", "Current finish time: %.6f" % (time.time() - start_time,))

		start_time = time.time()
		last_song = current[sid].get_song()
		if last_song:
			db.c.update("INSERT INTO r4_song_history (sid, song_id) VALUES (%s, %s)", (sid, last_song.id))
		log.debug("post", "Last song insertion time: %s" % (time.time() - start_time,))

		start_time = time.time()
		history[sid].insert(0, current[sid])
		while len(history[sid]) > 5:
			history[sid].pop()
		log.debug("post", "History management: %.6f" % (time.time() - start_time,))

		start_time = time.time()
		current[sid] = next[sid].pop(0)
		current[sid].start_event()
		log.debug("advance", "Current management: %.6f" % (time.time() - start_time,))

		start_time = time.time()
		# update_cache updates both the line and expiry times
		request.update_cache(sid)
		# reduce song blocks has to come first, otherwise it wll reduce blocks generated by _create_elections
		playlist.reduce_song_blocks(sid)
		# add to the event list / update start times for events
		manage_next(sid)
		log.debug("advance", "Next management: %.6f" % (time.time() - start_time,))

		start_time = time.time()
		_add_listener_count_record(sid)
		_trim(sid)
		user.trim_listeners(sid)
		cache.update_user_rating_acl(sid, history[sid][0].get_song().id)
		user.unlock_listeners(sid)
		log.debug("advance", "User management and trimming: %.6f" % (time.time() - start_time,))

		start_time = time.time()
		playlist.warm_cooled_songs(sid)
		playlist.warm_cooled_albums(sid)
		log.debug("advance", "Cooldown warming: %.6f" % (time.time() - start_time,))

		_update_memcache(sid)
		sync_to_front.sync_frontend_all(sid)
		db.c.commit()
	except:
		db.c.rollback()
		raise

# def refresh_schedule(sid):
# 	integrate_new_events(sid)
# 	sort_next(sid)
# 	_update_memcache(sid)
# 	sync_to_front.sync_frontend_all_timed(sid)

def _add_listener_count_record(sid):
	lc_guests = db.c.fetch_var("SELECT COUNT(*) FROM r4_listeners WHERE sid = %s AND listener_purge = FALSE AND user_id = 1", (sid,))
	lc_users = db.c.fetch_var("SELECT COUNT(*) FROM r4_listeners WHERE sid = %s AND listener_purge = FALSE AND user_id > 1", (sid,))
	lc_guests_active = db.c.fetch_var("SELECT COUNT(*) FROM r4_listeners WHERE sid = %s AND listener_purge = FALSE AND user_id = 1 AND listener_voted_entry IS NOT NULL", (sid,))
	lc_users_active = db.c.fetch_var("SELECT COUNT(*) FROM r4_listeners WHERE sid = %s AND listener_purge = FALSE AND user_id > 1 AND listener_voted_entry IS NOT NULL", (sid,))
	return db.c.update("INSERT INTO r4_listener_counts (sid, lc_guests, lc_users, lc_guests_active, lc_users_active) VALUES (%s, %s, %s, %s, %s)", (sid, lc_guests, lc_users, lc_guests_active, lc_users_active))

def _get_schedule_stats(sid):
	global next
	global current
	
	max_sched_id = 0
	max_elec_id = None
	end_time = int(time.time())
	if sid in current and current[sid]:
		max_sched_id = current[sid].id
		if current[sid].start_actual:
			end_time = current[sid].start_actual + current[sid].length()
		else:
			end_time += current[sid].length()
		if current[sid].is_election:
			max_elec_id = current[sid].id
	num_elections = 0

	if sid in next:
		for e in next[sid]:
			if e.is_election:
				num_elections += 1
				if e.id > max_elec_id:
					max_elec_id = e.id
			elif not e.is_election and e.id > max_sched_id:
				max_sched_id = e.id
			end_time += e.length()

	if not max_elec_id:
		max_elec_id = db.c.fetch_var("SELECT elec_id FROM r4_elections WHERE elec_used = TRUE ORDER BY elec_id DESC LIMIT 1")

	return (max_sched_id, max_elec_id, num_elections, end_time)

def manage_next(sid):
	max_sched_id, max_elec_id, num_elections, max_future_time = _get_schedule_stats(sid)
	next_producer = get_producer_at_time(sid, max_future_time)
	nextnext_producer_start = db.c.fetch_var("SELECT sched_start FROM r4_schedule WHERE sid = %s AND sched_used = FALSE AND sched_start > %s AND sched_timed = TRUE", (sid, max_future_time))
	time_to_future_producer = None
	if nextnext_producer_start:
		time_to_future_producer = nextnext_producer_start - max_future_time
	else:
		time_to_future_producer = 86400
	while len(next[sid]) < next_producer.plan_ahead_limit:
		target_length = None
		skip_requests = False
		if time < 20:
			pass
			log.debug("timing", "SID %s <20 seconds to next event, not using timing." % sid)
		if time_to_future_producer < 40:
			target_length = time_to_future_producer
			skip_requests = True
			next_producer = rainwave.events.shortest_election.ShortestElectionProducer(sid)
			log.debug("timing", "SID %s <40 seconds to next event, using shortest elections." % sid)
		elif time_to_future_producer < (playlist.get_average_song_length(sid) * 1.3):
			target_length = time_to_future_producer
			skip_requests = True
			log.debug("timing", "SID %s close to event, timing to %s seconds long." % (sid, target_length))
		elif time_to_future_producer < (playlist.get_average_song_length(sid) * 2.2):
			target_length = playlist.get_average_song_length(sid)
			log.debug("timing", "SID %s has an upcoming event, timing to %s seconds long." % (sid, target_length))
		next_event = next_producer.load_next_event(target_length, max_elec_id)
		if not next_event:
			log.info("manage_next", "Producer ID %s type %s did not produce an event." % (next_producer.id, next_producer.type))
			ep = election.ElectionProducer(sid)
			next_event = ep.load_next_event(target_length, max_elec_id)
		next[sid].append(next_event)
		if next_event.is_election and next_event.id > max_elec_id:
			max_elec_id = next_event.id
		max_future_time += next[sid][-1].length()
		time_to_future_producer -= next[sid][-1].length()
		next_producer = get_producer_at_time(sid, max_future_time)

	future_time = None
	if current[sid].start:
		future_time = current[sid].start + current[sid].length()
	else:
		future_time = int(time.time() + current[sid].length())
	for evt in next[sid]:
		evt.start = future_time
		future_time += evt.length()

def _get_or_create_election(sid, target_length = None):
	max_sched_id, max_elec_id, num_elections, next_end_time = _get_schedule_stats(sid)

	ep = election.ElectionProducer(sid)
	return ep.load_next_event(target_length=target_length, min_elec_id=max_elec_id)

def _trim(sid):
	# Deletes any events in the schedule and elections tables that are old, according to the config
	current_time = int(time.time())
	db.c.update("DELETE FROM r4_schedule WHERE sched_start_actual <= %s", (current_time - config.get("trim_event_age"),))
	db.c.update("DELETE FROM r4_elections WHERE elec_start_actual <= %s", (current_time - config.get("trim_election_age"),))
	max_history_id = db.c.fetch_var("SELECT MAX(songhist_id) FROM r4_song_history")
	db.c.update("DELETE FROM r4_song_history WHERE songhist_id <= %s", (max_history_id - config.get("trim_history_length"),))
	db.c.update("DELETE FROM r4_listener_counts WHERE lc_time <= %s", (current_time - config.get("trim_history_length"),))

def _update_schedule_memcache(sid):
	cache.set_station(sid, "sched_current", current[sid], True)
	cache.set_station(sid, "sched_next", next[sid], True)
	cache.set_station(sid, "sched_history", history[sid], True)

def _update_memcache(sid):
	_update_schedule_memcache(sid)
	sched_current_dict = current[sid].to_dict()
	cache.set_station(sid, "sched_current_dict", sched_current_dict, True)
	next_dict_list = []
	for event in next[sid]:
		next_dict_list.append(event.to_dict())
	cache.set_station(sid, "sched_next_dict", next_dict_list, True)
	history_dict_list = []
	for event in history[sid]:
		history_dict_list.append(event.to_dict())
	cache.set_station(sid, "sched_history_dict", history_dict_list, True)
	cache.prime_rating_cache_for_events([ current[sid] ] + next[sid] + history[sid])
	cache.set_station(sid, "current_listeners", listeners.get_listeners_dict(sid), True)
	cache.set_station(sid, "album_diff", playlist.get_updated_albums_dict(sid), True)
	playlist.clear_updated_albums(sid)
	cache.set_station(sid, "all_albums", playlist.get_all_albums_list(sid), True)
	cache.set_station(sid, "all_artists", playlist.get_all_artists_list(sid), True)

	all_station = {}
	if 'songs' in sched_current_dict:
		all_station['title'] = sched_current_dict['songs'][0]['title']
		all_station['album'] = sched_current_dict['songs'][0]['albums'][0]['name']
		all_station['art'] = sched_current_dict['songs'][0]['albums'][0]['art']
	else:
		all_station['title'] = sched_current_dict['name']
		all_station['album'] = ""
		all_station['art'] = None
	cache.set_station(sid, "all_station_info", all_station, True)